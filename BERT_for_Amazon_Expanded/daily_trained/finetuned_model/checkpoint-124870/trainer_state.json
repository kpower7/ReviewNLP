{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 124870,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00800832866180828,
      "grad_norm": 4.341034412384033,
      "learning_rate": 4.986652785563653e-05,
      "loss": 0.7995,
      "step": 500
    },
    {
      "epoch": 0.01601665732361656,
      "grad_norm": 4.903304576873779,
      "learning_rate": 4.973305571127306e-05,
      "loss": 0.6779,
      "step": 1000
    },
    {
      "epoch": 0.02402498598542484,
      "grad_norm": 7.063520908355713,
      "learning_rate": 4.959958356690959e-05,
      "loss": 0.6516,
      "step": 1500
    },
    {
      "epoch": 0.03203331464723312,
      "grad_norm": 3.4154152870178223,
      "learning_rate": 4.946611142254612e-05,
      "loss": 0.6306,
      "step": 2000
    },
    {
      "epoch": 0.040041643309041405,
      "grad_norm": 4.487967014312744,
      "learning_rate": 4.9332639278182645e-05,
      "loss": 0.6084,
      "step": 2500
    },
    {
      "epoch": 0.04804997197084968,
      "grad_norm": 5.1551971435546875,
      "learning_rate": 4.9199167133819176e-05,
      "loss": 0.6201,
      "step": 3000
    },
    {
      "epoch": 0.056058300632657966,
      "grad_norm": 6.992980003356934,
      "learning_rate": 4.90656949894557e-05,
      "loss": 0.6138,
      "step": 3500
    },
    {
      "epoch": 0.06406662929446624,
      "grad_norm": 14.44216537475586,
      "learning_rate": 4.893222284509223e-05,
      "loss": 0.5986,
      "step": 4000
    },
    {
      "epoch": 0.07207495795627453,
      "grad_norm": 5.647764205932617,
      "learning_rate": 4.879875070072876e-05,
      "loss": 0.6008,
      "step": 4500
    },
    {
      "epoch": 0.08008328661808281,
      "grad_norm": 6.318582534790039,
      "learning_rate": 4.8665278556365293e-05,
      "loss": 0.5978,
      "step": 5000
    },
    {
      "epoch": 0.08809161527989108,
      "grad_norm": 3.0823676586151123,
      "learning_rate": 4.853180641200182e-05,
      "loss": 0.6041,
      "step": 5500
    },
    {
      "epoch": 0.09609994394169936,
      "grad_norm": 3.658535957336426,
      "learning_rate": 4.839833426763835e-05,
      "loss": 0.5961,
      "step": 6000
    },
    {
      "epoch": 0.10410827260350765,
      "grad_norm": 9.705808639526367,
      "learning_rate": 4.826486212327487e-05,
      "loss": 0.575,
      "step": 6500
    },
    {
      "epoch": 0.11211660126531593,
      "grad_norm": 4.798050880432129,
      "learning_rate": 4.81313899789114e-05,
      "loss": 0.5939,
      "step": 7000
    },
    {
      "epoch": 0.12012492992712422,
      "grad_norm": 3.745378255844116,
      "learning_rate": 4.7997917834547936e-05,
      "loss": 0.5876,
      "step": 7500
    },
    {
      "epoch": 0.12813325858893249,
      "grad_norm": 6.620859146118164,
      "learning_rate": 4.786444569018446e-05,
      "loss": 0.5834,
      "step": 8000
    },
    {
      "epoch": 0.13614158725074077,
      "grad_norm": 6.508619785308838,
      "learning_rate": 4.773097354582099e-05,
      "loss": 0.5811,
      "step": 8500
    },
    {
      "epoch": 0.14414991591254905,
      "grad_norm": 3.5845539569854736,
      "learning_rate": 4.7597501401457515e-05,
      "loss": 0.586,
      "step": 9000
    },
    {
      "epoch": 0.15215824457435734,
      "grad_norm": 3.8543505668640137,
      "learning_rate": 4.7464029257094047e-05,
      "loss": 0.5764,
      "step": 9500
    },
    {
      "epoch": 0.16016657323616562,
      "grad_norm": 6.021883964538574,
      "learning_rate": 4.733055711273058e-05,
      "loss": 0.5818,
      "step": 10000
    },
    {
      "epoch": 0.1681749018979739,
      "grad_norm": 5.576465129852295,
      "learning_rate": 4.719708496836711e-05,
      "loss": 0.5723,
      "step": 10500
    },
    {
      "epoch": 0.17618323055978216,
      "grad_norm": 24.022804260253906,
      "learning_rate": 4.706361282400363e-05,
      "loss": 0.5747,
      "step": 11000
    },
    {
      "epoch": 0.18419155922159045,
      "grad_norm": 8.683987617492676,
      "learning_rate": 4.6930140679640164e-05,
      "loss": 0.5779,
      "step": 11500
    },
    {
      "epoch": 0.19219988788339873,
      "grad_norm": 9.578516006469727,
      "learning_rate": 4.679666853527669e-05,
      "loss": 0.5902,
      "step": 12000
    },
    {
      "epoch": 0.200208216545207,
      "grad_norm": 6.387156963348389,
      "learning_rate": 4.666319639091321e-05,
      "loss": 0.5706,
      "step": 12500
    },
    {
      "epoch": 0.2082165452070153,
      "grad_norm": 7.460468292236328,
      "learning_rate": 4.652972424654975e-05,
      "loss": 0.5753,
      "step": 13000
    },
    {
      "epoch": 0.21622487386882358,
      "grad_norm": 2.5201504230499268,
      "learning_rate": 4.6396252102186275e-05,
      "loss": 0.5617,
      "step": 13500
    },
    {
      "epoch": 0.22423320253063186,
      "grad_norm": 10.917168617248535,
      "learning_rate": 4.6262779957822806e-05,
      "loss": 0.5789,
      "step": 14000
    },
    {
      "epoch": 0.23224153119244015,
      "grad_norm": 4.143006801605225,
      "learning_rate": 4.612930781345933e-05,
      "loss": 0.5796,
      "step": 14500
    },
    {
      "epoch": 0.24024985985424843,
      "grad_norm": 5.7884907722473145,
      "learning_rate": 4.599583566909586e-05,
      "loss": 0.5753,
      "step": 15000
    },
    {
      "epoch": 0.2482581885160567,
      "grad_norm": 3.828791856765747,
      "learning_rate": 4.5862363524732386e-05,
      "loss": 0.5697,
      "step": 15500
    },
    {
      "epoch": 0.25626651717786497,
      "grad_norm": 4.151005268096924,
      "learning_rate": 4.5728891380368924e-05,
      "loss": 0.5676,
      "step": 16000
    },
    {
      "epoch": 0.26427484583967326,
      "grad_norm": 2.498488426208496,
      "learning_rate": 4.559541923600545e-05,
      "loss": 0.584,
      "step": 16500
    },
    {
      "epoch": 0.27228317450148154,
      "grad_norm": 7.905001163482666,
      "learning_rate": 4.546194709164198e-05,
      "loss": 0.5704,
      "step": 17000
    },
    {
      "epoch": 0.2802915031632898,
      "grad_norm": 5.520227909088135,
      "learning_rate": 4.5328474947278504e-05,
      "loss": 0.5705,
      "step": 17500
    },
    {
      "epoch": 0.2882998318250981,
      "grad_norm": 3.0246224403381348,
      "learning_rate": 4.5195002802915035e-05,
      "loss": 0.5685,
      "step": 18000
    },
    {
      "epoch": 0.2963081604869064,
      "grad_norm": 3.9577836990356445,
      "learning_rate": 4.5061530658551566e-05,
      "loss": 0.5672,
      "step": 18500
    },
    {
      "epoch": 0.3043164891487147,
      "grad_norm": 3.936753988265991,
      "learning_rate": 4.492805851418809e-05,
      "loss": 0.5723,
      "step": 19000
    },
    {
      "epoch": 0.31232481781052296,
      "grad_norm": 9.493486404418945,
      "learning_rate": 4.479458636982462e-05,
      "loss": 0.5821,
      "step": 19500
    },
    {
      "epoch": 0.32033314647233124,
      "grad_norm": 4.156578063964844,
      "learning_rate": 4.4661114225461146e-05,
      "loss": 0.5514,
      "step": 20000
    },
    {
      "epoch": 0.3283414751341395,
      "grad_norm": 3.5540716648101807,
      "learning_rate": 4.452764208109768e-05,
      "loss": 0.5495,
      "step": 20500
    },
    {
      "epoch": 0.3363498037959478,
      "grad_norm": 3.091482162475586,
      "learning_rate": 4.43941699367342e-05,
      "loss": 0.5689,
      "step": 21000
    },
    {
      "epoch": 0.34435813245775604,
      "grad_norm": 2.9373323917388916,
      "learning_rate": 4.426069779237074e-05,
      "loss": 0.5602,
      "step": 21500
    },
    {
      "epoch": 0.3523664611195643,
      "grad_norm": 2.800938129425049,
      "learning_rate": 4.4127225648007264e-05,
      "loss": 0.5615,
      "step": 22000
    },
    {
      "epoch": 0.3603747897813726,
      "grad_norm": 5.757203102111816,
      "learning_rate": 4.3993753503643795e-05,
      "loss": 0.5678,
      "step": 22500
    },
    {
      "epoch": 0.3683831184431809,
      "grad_norm": 3.7301228046417236,
      "learning_rate": 4.386028135928032e-05,
      "loss": 0.5777,
      "step": 23000
    },
    {
      "epoch": 0.3763914471049892,
      "grad_norm": 32.20902633666992,
      "learning_rate": 4.372680921491685e-05,
      "loss": 0.576,
      "step": 23500
    },
    {
      "epoch": 0.38439977576679746,
      "grad_norm": 4.901029586791992,
      "learning_rate": 4.3593337070553375e-05,
      "loss": 0.588,
      "step": 24000
    },
    {
      "epoch": 0.39240810442860574,
      "grad_norm": 4.396781921386719,
      "learning_rate": 4.3459864926189906e-05,
      "loss": 0.5851,
      "step": 24500
    },
    {
      "epoch": 0.400416433090414,
      "grad_norm": 4.765368461608887,
      "learning_rate": 4.332639278182644e-05,
      "loss": 0.5777,
      "step": 25000
    },
    {
      "epoch": 0.4084247617522223,
      "grad_norm": 10.55105972290039,
      "learning_rate": 4.319292063746296e-05,
      "loss": 0.5738,
      "step": 25500
    },
    {
      "epoch": 0.4164330904140306,
      "grad_norm": 5.845773220062256,
      "learning_rate": 4.305944849309949e-05,
      "loss": 0.5807,
      "step": 26000
    },
    {
      "epoch": 0.4244414190758389,
      "grad_norm": 7.819371700286865,
      "learning_rate": 4.292597634873602e-05,
      "loss": 0.5591,
      "step": 26500
    },
    {
      "epoch": 0.43244974773764716,
      "grad_norm": 2.8302836418151855,
      "learning_rate": 4.2792504204372555e-05,
      "loss": 0.5691,
      "step": 27000
    },
    {
      "epoch": 0.44045807639945544,
      "grad_norm": 10.305069923400879,
      "learning_rate": 4.265903206000908e-05,
      "loss": 0.552,
      "step": 27500
    },
    {
      "epoch": 0.44846640506126373,
      "grad_norm": 6.313445091247559,
      "learning_rate": 4.252555991564561e-05,
      "loss": 0.5567,
      "step": 28000
    },
    {
      "epoch": 0.456474733723072,
      "grad_norm": 4.808748245239258,
      "learning_rate": 4.2392087771282135e-05,
      "loss": 0.5686,
      "step": 28500
    },
    {
      "epoch": 0.4644830623848803,
      "grad_norm": 5.541644096374512,
      "learning_rate": 4.2258615626918666e-05,
      "loss": 0.562,
      "step": 29000
    },
    {
      "epoch": 0.4724913910466886,
      "grad_norm": 3.016921281814575,
      "learning_rate": 4.212514348255519e-05,
      "loss": 0.5752,
      "step": 29500
    },
    {
      "epoch": 0.48049971970849686,
      "grad_norm": 1.342978596687317,
      "learning_rate": 4.199167133819172e-05,
      "loss": 0.5676,
      "step": 30000
    },
    {
      "epoch": 0.4885080483703051,
      "grad_norm": 2.043856620788574,
      "learning_rate": 4.185819919382825e-05,
      "loss": 0.5774,
      "step": 30500
    },
    {
      "epoch": 0.4965163770321134,
      "grad_norm": 5.0765299797058105,
      "learning_rate": 4.172472704946478e-05,
      "loss": 0.5716,
      "step": 31000
    },
    {
      "epoch": 0.5045247056939217,
      "grad_norm": 5.079748630523682,
      "learning_rate": 4.159125490510131e-05,
      "loss": 0.5598,
      "step": 31500
    },
    {
      "epoch": 0.5125330343557299,
      "grad_norm": 3.0093252658843994,
      "learning_rate": 4.145778276073783e-05,
      "loss": 0.5828,
      "step": 32000
    },
    {
      "epoch": 0.5205413630175383,
      "grad_norm": 3.962170362472534,
      "learning_rate": 4.1324310616374364e-05,
      "loss": 0.5496,
      "step": 32500
    },
    {
      "epoch": 0.5285496916793465,
      "grad_norm": 3.651639223098755,
      "learning_rate": 4.1190838472010895e-05,
      "loss": 0.5586,
      "step": 33000
    },
    {
      "epoch": 0.5365580203411549,
      "grad_norm": 4.153874397277832,
      "learning_rate": 4.1057366327647426e-05,
      "loss": 0.5602,
      "step": 33500
    },
    {
      "epoch": 0.5445663490029631,
      "grad_norm": 4.265336990356445,
      "learning_rate": 4.092389418328395e-05,
      "loss": 0.5628,
      "step": 34000
    },
    {
      "epoch": 0.5525746776647713,
      "grad_norm": 7.398928642272949,
      "learning_rate": 4.079042203892048e-05,
      "loss": 0.5575,
      "step": 34500
    },
    {
      "epoch": 0.5605830063265796,
      "grad_norm": 2.9150454998016357,
      "learning_rate": 4.0656949894557006e-05,
      "loss": 0.5655,
      "step": 35000
    },
    {
      "epoch": 0.5685913349883879,
      "grad_norm": 10.627225875854492,
      "learning_rate": 4.052347775019354e-05,
      "loss": 0.5556,
      "step": 35500
    },
    {
      "epoch": 0.5765996636501962,
      "grad_norm": 5.627581596374512,
      "learning_rate": 4.039000560583007e-05,
      "loss": 0.5658,
      "step": 36000
    },
    {
      "epoch": 0.5846079923120044,
      "grad_norm": 4.279469013214111,
      "learning_rate": 4.025653346146659e-05,
      "loss": 0.5489,
      "step": 36500
    },
    {
      "epoch": 0.5926163209738128,
      "grad_norm": 2.1071250438690186,
      "learning_rate": 4.0123061317103124e-05,
      "loss": 0.5657,
      "step": 37000
    },
    {
      "epoch": 0.600624649635621,
      "grad_norm": 4.208123207092285,
      "learning_rate": 3.998958917273965e-05,
      "loss": 0.5634,
      "step": 37500
    },
    {
      "epoch": 0.6086329782974294,
      "grad_norm": 6.990226745605469,
      "learning_rate": 3.985611702837618e-05,
      "loss": 0.5506,
      "step": 38000
    },
    {
      "epoch": 0.6166413069592376,
      "grad_norm": 3.9392850399017334,
      "learning_rate": 3.972264488401271e-05,
      "loss": 0.5653,
      "step": 38500
    },
    {
      "epoch": 0.6246496356210459,
      "grad_norm": 4.577337265014648,
      "learning_rate": 3.958917273964924e-05,
      "loss": 0.5529,
      "step": 39000
    },
    {
      "epoch": 0.6326579642828541,
      "grad_norm": 4.566893577575684,
      "learning_rate": 3.9455700595285766e-05,
      "loss": 0.5548,
      "step": 39500
    },
    {
      "epoch": 0.6406662929446625,
      "grad_norm": 5.411877632141113,
      "learning_rate": 3.93222284509223e-05,
      "loss": 0.5537,
      "step": 40000
    },
    {
      "epoch": 0.6486746216064707,
      "grad_norm": 4.104384422302246,
      "learning_rate": 3.918875630655882e-05,
      "loss": 0.5651,
      "step": 40500
    },
    {
      "epoch": 0.656682950268279,
      "grad_norm": 2.938718557357788,
      "learning_rate": 3.905528416219535e-05,
      "loss": 0.566,
      "step": 41000
    },
    {
      "epoch": 0.6646912789300873,
      "grad_norm": 3.550554037094116,
      "learning_rate": 3.8921812017831883e-05,
      "loss": 0.5546,
      "step": 41500
    },
    {
      "epoch": 0.6726996075918956,
      "grad_norm": 1.508626103401184,
      "learning_rate": 3.878833987346841e-05,
      "loss": 0.5534,
      "step": 42000
    },
    {
      "epoch": 0.6807079362537038,
      "grad_norm": 2.913686752319336,
      "learning_rate": 3.865486772910494e-05,
      "loss": 0.5476,
      "step": 42500
    },
    {
      "epoch": 0.6887162649155121,
      "grad_norm": 3.9451050758361816,
      "learning_rate": 3.852139558474146e-05,
      "loss": 0.5494,
      "step": 43000
    },
    {
      "epoch": 0.6967245935773204,
      "grad_norm": 3.3587934970855713,
      "learning_rate": 3.8387923440377994e-05,
      "loss": 0.5487,
      "step": 43500
    },
    {
      "epoch": 0.7047329222391286,
      "grad_norm": 1.7476997375488281,
      "learning_rate": 3.8254451296014526e-05,
      "loss": 0.537,
      "step": 44000
    },
    {
      "epoch": 0.712741250900937,
      "grad_norm": 4.126948833465576,
      "learning_rate": 3.812097915165106e-05,
      "loss": 0.5448,
      "step": 44500
    },
    {
      "epoch": 0.7207495795627452,
      "grad_norm": 4.941864967346191,
      "learning_rate": 3.798750700728758e-05,
      "loss": 0.567,
      "step": 45000
    },
    {
      "epoch": 0.7287579082245536,
      "grad_norm": 3.1921803951263428,
      "learning_rate": 3.785403486292411e-05,
      "loss": 0.5621,
      "step": 45500
    },
    {
      "epoch": 0.7367662368863618,
      "grad_norm": 3.7173779010772705,
      "learning_rate": 3.7720562718560637e-05,
      "loss": 0.5479,
      "step": 46000
    },
    {
      "epoch": 0.7447745655481701,
      "grad_norm": 2.963423252105713,
      "learning_rate": 3.758709057419717e-05,
      "loss": 0.5611,
      "step": 46500
    },
    {
      "epoch": 0.7527828942099783,
      "grad_norm": 5.177140235900879,
      "learning_rate": 3.74536184298337e-05,
      "loss": 0.5445,
      "step": 47000
    },
    {
      "epoch": 0.7607912228717867,
      "grad_norm": 3.394289255142212,
      "learning_rate": 3.732014628547022e-05,
      "loss": 0.5473,
      "step": 47500
    },
    {
      "epoch": 0.7687995515335949,
      "grad_norm": 10.127290725708008,
      "learning_rate": 3.7186674141106754e-05,
      "loss": 0.5494,
      "step": 48000
    },
    {
      "epoch": 0.7768078801954033,
      "grad_norm": 5.279999256134033,
      "learning_rate": 3.705320199674328e-05,
      "loss": 0.5584,
      "step": 48500
    },
    {
      "epoch": 0.7848162088572115,
      "grad_norm": 13.918063163757324,
      "learning_rate": 3.691972985237981e-05,
      "loss": 0.5715,
      "step": 49000
    },
    {
      "epoch": 0.7928245375190198,
      "grad_norm": 5.973888397216797,
      "learning_rate": 3.6786257708016334e-05,
      "loss": 0.5735,
      "step": 49500
    },
    {
      "epoch": 0.800832866180828,
      "grad_norm": 17.23167610168457,
      "learning_rate": 3.665278556365287e-05,
      "loss": 0.5735,
      "step": 50000
    },
    {
      "epoch": 0.8088411948426364,
      "grad_norm": 3.0458498001098633,
      "learning_rate": 3.6519313419289396e-05,
      "loss": 0.6101,
      "step": 50500
    },
    {
      "epoch": 0.8168495235044446,
      "grad_norm": 5.47400426864624,
      "learning_rate": 3.638584127492593e-05,
      "loss": 0.569,
      "step": 51000
    },
    {
      "epoch": 0.824857852166253,
      "grad_norm": 3.2479183673858643,
      "learning_rate": 3.625236913056245e-05,
      "loss": 0.5747,
      "step": 51500
    },
    {
      "epoch": 0.8328661808280612,
      "grad_norm": 8.307097434997559,
      "learning_rate": 3.611889698619898e-05,
      "loss": 0.5658,
      "step": 52000
    },
    {
      "epoch": 0.8408745094898694,
      "grad_norm": 3.029916763305664,
      "learning_rate": 3.5985424841835514e-05,
      "loss": 0.5746,
      "step": 52500
    },
    {
      "epoch": 0.8488828381516778,
      "grad_norm": 3.647195339202881,
      "learning_rate": 3.585195269747204e-05,
      "loss": 0.6002,
      "step": 53000
    },
    {
      "epoch": 0.856891166813486,
      "grad_norm": 2.2078123092651367,
      "learning_rate": 3.571848055310857e-05,
      "loss": 0.5973,
      "step": 53500
    },
    {
      "epoch": 0.8648994954752943,
      "grad_norm": 4.585103511810303,
      "learning_rate": 3.5585008408745094e-05,
      "loss": 0.6071,
      "step": 54000
    },
    {
      "epoch": 0.8729078241371026,
      "grad_norm": 30.27272605895996,
      "learning_rate": 3.5451536264381625e-05,
      "loss": 0.5817,
      "step": 54500
    },
    {
      "epoch": 0.8809161527989109,
      "grad_norm": 3.619690418243408,
      "learning_rate": 3.531806412001815e-05,
      "loss": 0.6166,
      "step": 55000
    },
    {
      "epoch": 0.8889244814607191,
      "grad_norm": 4.975050449371338,
      "learning_rate": 3.518459197565469e-05,
      "loss": 0.618,
      "step": 55500
    },
    {
      "epoch": 0.8969328101225275,
      "grad_norm": 2.7916760444641113,
      "learning_rate": 3.505111983129121e-05,
      "loss": 0.5827,
      "step": 56000
    },
    {
      "epoch": 0.9049411387843357,
      "grad_norm": 2.5821750164031982,
      "learning_rate": 3.491764768692774e-05,
      "loss": 0.5558,
      "step": 56500
    },
    {
      "epoch": 0.912949467446144,
      "grad_norm": 11.432326316833496,
      "learning_rate": 3.478417554256427e-05,
      "loss": 0.5964,
      "step": 57000
    },
    {
      "epoch": 0.9209577961079523,
      "grad_norm": 7.981192111968994,
      "learning_rate": 3.46507033982008e-05,
      "loss": 0.5874,
      "step": 57500
    },
    {
      "epoch": 0.9289661247697606,
      "grad_norm": 8.353496551513672,
      "learning_rate": 3.451723125383732e-05,
      "loss": 0.6429,
      "step": 58000
    },
    {
      "epoch": 0.9369744534315688,
      "grad_norm": 3.98939847946167,
      "learning_rate": 3.4383759109473854e-05,
      "loss": 0.6455,
      "step": 58500
    },
    {
      "epoch": 0.9449827820933772,
      "grad_norm": 8.27649974822998,
      "learning_rate": 3.4250286965110385e-05,
      "loss": 0.5744,
      "step": 59000
    },
    {
      "epoch": 0.9529911107551854,
      "grad_norm": 3.5062062740325928,
      "learning_rate": 3.411681482074691e-05,
      "loss": 0.5702,
      "step": 59500
    },
    {
      "epoch": 0.9609994394169937,
      "grad_norm": 15.206467628479004,
      "learning_rate": 3.398334267638344e-05,
      "loss": 0.5758,
      "step": 60000
    },
    {
      "epoch": 0.969007768078802,
      "grad_norm": 17.04636573791504,
      "learning_rate": 3.3849870532019965e-05,
      "loss": 0.5856,
      "step": 60500
    },
    {
      "epoch": 0.9770160967406102,
      "grad_norm": 6.201862812042236,
      "learning_rate": 3.37163983876565e-05,
      "loss": 0.6112,
      "step": 61000
    },
    {
      "epoch": 0.9850244254024185,
      "grad_norm": 5.430823802947998,
      "learning_rate": 3.358292624329303e-05,
      "loss": 0.6022,
      "step": 61500
    },
    {
      "epoch": 0.9930327540642268,
      "grad_norm": 12.381128311157227,
      "learning_rate": 3.344945409892956e-05,
      "loss": 0.5864,
      "step": 62000
    },
    {
      "epoch": 1.001041082726035,
      "grad_norm": 4.036890029907227,
      "learning_rate": 3.331598195456608e-05,
      "loss": 0.5762,
      "step": 62500
    },
    {
      "epoch": 1.0090494113878434,
      "grad_norm": 3.122976541519165,
      "learning_rate": 3.3182509810202614e-05,
      "loss": 0.6011,
      "step": 63000
    },
    {
      "epoch": 1.0170577400496517,
      "grad_norm": 2.9697132110595703,
      "learning_rate": 3.304903766583914e-05,
      "loss": 0.5758,
      "step": 63500
    },
    {
      "epoch": 1.0250660687114599,
      "grad_norm": 7.880277156829834,
      "learning_rate": 3.291556552147567e-05,
      "loss": 0.5538,
      "step": 64000
    },
    {
      "epoch": 1.0330743973732681,
      "grad_norm": 10.287847518920898,
      "learning_rate": 3.27820933771122e-05,
      "loss": 0.5684,
      "step": 64500
    },
    {
      "epoch": 1.0410827260350766,
      "grad_norm": 29.196542739868164,
      "learning_rate": 3.2648621232748725e-05,
      "loss": 0.5852,
      "step": 65000
    },
    {
      "epoch": 1.0490910546968848,
      "grad_norm": 13.388043403625488,
      "learning_rate": 3.2515149088385256e-05,
      "loss": 0.5929,
      "step": 65500
    },
    {
      "epoch": 1.057099383358693,
      "grad_norm": 2.2638657093048096,
      "learning_rate": 3.238167694402178e-05,
      "loss": 0.5985,
      "step": 66000
    },
    {
      "epoch": 1.0651077120205013,
      "grad_norm": 46.76168441772461,
      "learning_rate": 3.224820479965831e-05,
      "loss": 0.5722,
      "step": 66500
    },
    {
      "epoch": 1.0731160406823097,
      "grad_norm": 10.283295631408691,
      "learning_rate": 3.211473265529484e-05,
      "loss": 0.5599,
      "step": 67000
    },
    {
      "epoch": 1.081124369344118,
      "grad_norm": 4.871533393859863,
      "learning_rate": 3.1981260510931374e-05,
      "loss": 0.5426,
      "step": 67500
    },
    {
      "epoch": 1.0891326980059262,
      "grad_norm": 4.29221248626709,
      "learning_rate": 3.18477883665679e-05,
      "loss": 0.5692,
      "step": 68000
    },
    {
      "epoch": 1.0971410266677344,
      "grad_norm": 21.451339721679688,
      "learning_rate": 3.171431622220443e-05,
      "loss": 0.5576,
      "step": 68500
    },
    {
      "epoch": 1.1051493553295426,
      "grad_norm": 5.6028666496276855,
      "learning_rate": 3.1580844077840954e-05,
      "loss": 0.5685,
      "step": 69000
    },
    {
      "epoch": 1.113157683991351,
      "grad_norm": 4.469378471374512,
      "learning_rate": 3.1447371933477485e-05,
      "loss": 0.5372,
      "step": 69500
    },
    {
      "epoch": 1.1211660126531593,
      "grad_norm": 6.250676155090332,
      "learning_rate": 3.1313899789114016e-05,
      "loss": 0.528,
      "step": 70000
    },
    {
      "epoch": 1.1291743413149675,
      "grad_norm": 2.7597177028656006,
      "learning_rate": 3.118042764475054e-05,
      "loss": 0.525,
      "step": 70500
    },
    {
      "epoch": 1.1371826699767758,
      "grad_norm": 3.4835798740386963,
      "learning_rate": 3.104695550038707e-05,
      "loss": 0.5368,
      "step": 71000
    },
    {
      "epoch": 1.1451909986385842,
      "grad_norm": 4.725292205810547,
      "learning_rate": 3.0913483356023596e-05,
      "loss": 0.53,
      "step": 71500
    },
    {
      "epoch": 1.1531993273003924,
      "grad_norm": 4.831820487976074,
      "learning_rate": 3.078001121166013e-05,
      "loss": 0.5339,
      "step": 72000
    },
    {
      "epoch": 1.1612076559622007,
      "grad_norm": 3.886702537536621,
      "learning_rate": 3.064653906729666e-05,
      "loss": 0.5383,
      "step": 72500
    },
    {
      "epoch": 1.1692159846240089,
      "grad_norm": 2.8685832023620605,
      "learning_rate": 3.0513066922933186e-05,
      "loss": 0.5331,
      "step": 73000
    },
    {
      "epoch": 1.1772243132858173,
      "grad_norm": 13.397988319396973,
      "learning_rate": 3.0379594778569713e-05,
      "loss": 0.5253,
      "step": 73500
    },
    {
      "epoch": 1.1852326419476256,
      "grad_norm": 6.273265361785889,
      "learning_rate": 3.024612263420624e-05,
      "loss": 0.5244,
      "step": 74000
    },
    {
      "epoch": 1.1932409706094338,
      "grad_norm": 3.430068016052246,
      "learning_rate": 3.011265048984277e-05,
      "loss": 0.5544,
      "step": 74500
    },
    {
      "epoch": 1.201249299271242,
      "grad_norm": 160.6565704345703,
      "learning_rate": 2.9979178345479297e-05,
      "loss": 0.5334,
      "step": 75000
    },
    {
      "epoch": 1.2092576279330505,
      "grad_norm": 4.157841205596924,
      "learning_rate": 2.984570620111583e-05,
      "loss": 0.5325,
      "step": 75500
    },
    {
      "epoch": 1.2172659565948587,
      "grad_norm": 23.81913185119629,
      "learning_rate": 2.971223405675236e-05,
      "loss": 0.5385,
      "step": 76000
    },
    {
      "epoch": 1.225274285256667,
      "grad_norm": 6.362563133239746,
      "learning_rate": 2.9578761912388887e-05,
      "loss": 0.5406,
      "step": 76500
    },
    {
      "epoch": 1.2332826139184752,
      "grad_norm": 2.9250121116638184,
      "learning_rate": 2.9445289768025414e-05,
      "loss": 0.5285,
      "step": 77000
    },
    {
      "epoch": 1.2412909425802834,
      "grad_norm": 12.129765510559082,
      "learning_rate": 2.9311817623661942e-05,
      "loss": 0.5336,
      "step": 77500
    },
    {
      "epoch": 1.2492992712420918,
      "grad_norm": 4.581326007843018,
      "learning_rate": 2.9178345479298473e-05,
      "loss": 0.5289,
      "step": 78000
    },
    {
      "epoch": 1.2573075999039,
      "grad_norm": 10.895811080932617,
      "learning_rate": 2.9044873334935e-05,
      "loss": 0.544,
      "step": 78500
    },
    {
      "epoch": 1.2653159285657083,
      "grad_norm": 4.070727825164795,
      "learning_rate": 2.891140119057153e-05,
      "loss": 0.5162,
      "step": 79000
    },
    {
      "epoch": 1.2733242572275167,
      "grad_norm": 4.06965970993042,
      "learning_rate": 2.8777929046208057e-05,
      "loss": 0.5294,
      "step": 79500
    },
    {
      "epoch": 1.281332585889325,
      "grad_norm": 4.579061985015869,
      "learning_rate": 2.8644456901844584e-05,
      "loss": 0.52,
      "step": 80000
    },
    {
      "epoch": 1.2893409145511332,
      "grad_norm": 6.460152626037598,
      "learning_rate": 2.8510984757481112e-05,
      "loss": 0.5258,
      "step": 80500
    },
    {
      "epoch": 1.2973492432129414,
      "grad_norm": 7.23961877822876,
      "learning_rate": 2.8377512613117647e-05,
      "loss": 0.5414,
      "step": 81000
    },
    {
      "epoch": 1.3053575718747497,
      "grad_norm": 2.1204023361206055,
      "learning_rate": 2.8244040468754174e-05,
      "loss": 0.5283,
      "step": 81500
    },
    {
      "epoch": 1.3133659005365579,
      "grad_norm": 5.8042073249816895,
      "learning_rate": 2.8110568324390702e-05,
      "loss": 0.5444,
      "step": 82000
    },
    {
      "epoch": 1.3213742291983663,
      "grad_norm": 3.8973348140716553,
      "learning_rate": 2.797709618002723e-05,
      "loss": 0.5247,
      "step": 82500
    },
    {
      "epoch": 1.3293825578601746,
      "grad_norm": 2.659574508666992,
      "learning_rate": 2.7843624035663758e-05,
      "loss": 0.5288,
      "step": 83000
    },
    {
      "epoch": 1.3373908865219828,
      "grad_norm": 3.706261157989502,
      "learning_rate": 2.7710151891300285e-05,
      "loss": 0.532,
      "step": 83500
    },
    {
      "epoch": 1.3453992151837912,
      "grad_norm": 20.325761795043945,
      "learning_rate": 2.7576679746936817e-05,
      "loss": 0.5168,
      "step": 84000
    },
    {
      "epoch": 1.3534075438455995,
      "grad_norm": 2.9860475063323975,
      "learning_rate": 2.7443207602573344e-05,
      "loss": 0.5249,
      "step": 84500
    },
    {
      "epoch": 1.3614158725074077,
      "grad_norm": 5.427518367767334,
      "learning_rate": 2.7309735458209872e-05,
      "loss": 0.5167,
      "step": 85000
    },
    {
      "epoch": 1.369424201169216,
      "grad_norm": 6.439121246337891,
      "learning_rate": 2.71762633138464e-05,
      "loss": 0.5392,
      "step": 85500
    },
    {
      "epoch": 1.3774325298310242,
      "grad_norm": 8.334936141967773,
      "learning_rate": 2.7042791169482927e-05,
      "loss": 0.5157,
      "step": 86000
    },
    {
      "epoch": 1.3854408584928326,
      "grad_norm": 4.830845355987549,
      "learning_rate": 2.6909319025119462e-05,
      "loss": 0.5368,
      "step": 86500
    },
    {
      "epoch": 1.3934491871546408,
      "grad_norm": 2.1246495246887207,
      "learning_rate": 2.677584688075599e-05,
      "loss": 0.5088,
      "step": 87000
    },
    {
      "epoch": 1.401457515816449,
      "grad_norm": 2.3075292110443115,
      "learning_rate": 2.6642374736392518e-05,
      "loss": 0.5368,
      "step": 87500
    },
    {
      "epoch": 1.4094658444782575,
      "grad_norm": 2.213160514831543,
      "learning_rate": 2.6508902592029045e-05,
      "loss": 0.5422,
      "step": 88000
    },
    {
      "epoch": 1.4174741731400657,
      "grad_norm": 12.27783489227295,
      "learning_rate": 2.6375430447665573e-05,
      "loss": 0.5403,
      "step": 88500
    },
    {
      "epoch": 1.425482501801874,
      "grad_norm": 4.510140419006348,
      "learning_rate": 2.62419583033021e-05,
      "loss": 0.5352,
      "step": 89000
    },
    {
      "epoch": 1.4334908304636822,
      "grad_norm": 4.781023025512695,
      "learning_rate": 2.6108486158938632e-05,
      "loss": 0.5149,
      "step": 89500
    },
    {
      "epoch": 1.4414991591254904,
      "grad_norm": 6.79545783996582,
      "learning_rate": 2.597501401457516e-05,
      "loss": 0.5373,
      "step": 90000
    },
    {
      "epoch": 1.4495074877872987,
      "grad_norm": 49.147579193115234,
      "learning_rate": 2.5841541870211687e-05,
      "loss": 0.5313,
      "step": 90500
    },
    {
      "epoch": 1.457515816449107,
      "grad_norm": 2.4180684089660645,
      "learning_rate": 2.5708069725848215e-05,
      "loss": 0.5341,
      "step": 91000
    },
    {
      "epoch": 1.4655241451109153,
      "grad_norm": 4.6710968017578125,
      "learning_rate": 2.5574597581484743e-05,
      "loss": 0.5254,
      "step": 91500
    },
    {
      "epoch": 1.4735324737727236,
      "grad_norm": 13.610833168029785,
      "learning_rate": 2.544112543712127e-05,
      "loss": 0.5334,
      "step": 92000
    },
    {
      "epoch": 1.481540802434532,
      "grad_norm": 3.6180546283721924,
      "learning_rate": 2.5307653292757805e-05,
      "loss": 0.5404,
      "step": 92500
    },
    {
      "epoch": 1.4895491310963402,
      "grad_norm": 9.872357368469238,
      "learning_rate": 2.5174181148394333e-05,
      "loss": 0.5243,
      "step": 93000
    },
    {
      "epoch": 1.4975574597581485,
      "grad_norm": 11.83433723449707,
      "learning_rate": 2.504070900403086e-05,
      "loss": 0.5212,
      "step": 93500
    },
    {
      "epoch": 1.5055657884199567,
      "grad_norm": 5.849399566650391,
      "learning_rate": 2.490723685966739e-05,
      "loss": 0.536,
      "step": 94000
    },
    {
      "epoch": 1.513574117081765,
      "grad_norm": 6.792448043823242,
      "learning_rate": 2.477376471530392e-05,
      "loss": 0.5139,
      "step": 94500
    },
    {
      "epoch": 1.5215824457435732,
      "grad_norm": 10.482234954833984,
      "learning_rate": 2.4640292570940447e-05,
      "loss": 0.514,
      "step": 95000
    },
    {
      "epoch": 1.5295907744053816,
      "grad_norm": 3.7406227588653564,
      "learning_rate": 2.4506820426576975e-05,
      "loss": 0.5278,
      "step": 95500
    },
    {
      "epoch": 1.5375991030671898,
      "grad_norm": 5.730695724487305,
      "learning_rate": 2.4373348282213503e-05,
      "loss": 0.5093,
      "step": 96000
    },
    {
      "epoch": 1.5456074317289983,
      "grad_norm": 3.3730945587158203,
      "learning_rate": 2.423987613785003e-05,
      "loss": 0.5235,
      "step": 96500
    },
    {
      "epoch": 1.5536157603908065,
      "grad_norm": 3.492950916290283,
      "learning_rate": 2.4106403993486558e-05,
      "loss": 0.5175,
      "step": 97000
    },
    {
      "epoch": 1.5616240890526147,
      "grad_norm": 6.554967880249023,
      "learning_rate": 2.397293184912309e-05,
      "loss": 0.5368,
      "step": 97500
    },
    {
      "epoch": 1.569632417714423,
      "grad_norm": 2.112107515335083,
      "learning_rate": 2.3839459704759617e-05,
      "loss": 0.5272,
      "step": 98000
    },
    {
      "epoch": 1.5776407463762312,
      "grad_norm": 6.589860439300537,
      "learning_rate": 2.3705987560396145e-05,
      "loss": 0.5219,
      "step": 98500
    },
    {
      "epoch": 1.5856490750380394,
      "grad_norm": 9.147485733032227,
      "learning_rate": 2.3572515416032676e-05,
      "loss": 0.5768,
      "step": 99000
    },
    {
      "epoch": 1.5936574036998479,
      "grad_norm": 2.691847801208496,
      "learning_rate": 2.3439043271669204e-05,
      "loss": 0.5257,
      "step": 99500
    },
    {
      "epoch": 1.601665732361656,
      "grad_norm": 2.4653239250183105,
      "learning_rate": 2.3305571127305735e-05,
      "loss": 0.522,
      "step": 100000
    },
    {
      "epoch": 1.6096740610234646,
      "grad_norm": 11.085479736328125,
      "learning_rate": 2.3172098982942263e-05,
      "loss": 0.5168,
      "step": 100500
    },
    {
      "epoch": 1.6176823896852728,
      "grad_norm": 10.273331642150879,
      "learning_rate": 2.303862683857879e-05,
      "loss": 0.5353,
      "step": 101000
    },
    {
      "epoch": 1.625690718347081,
      "grad_norm": 2.038649559020996,
      "learning_rate": 2.2905154694215318e-05,
      "loss": 0.5202,
      "step": 101500
    },
    {
      "epoch": 1.6336990470088892,
      "grad_norm": 4.0400004386901855,
      "learning_rate": 2.2771682549851846e-05,
      "loss": 0.5176,
      "step": 102000
    },
    {
      "epoch": 1.6417073756706975,
      "grad_norm": 2.4204163551330566,
      "learning_rate": 2.2638210405488374e-05,
      "loss": 0.5092,
      "step": 102500
    },
    {
      "epoch": 1.6497157043325057,
      "grad_norm": 3.1426825523376465,
      "learning_rate": 2.2504738261124905e-05,
      "loss": 0.5198,
      "step": 103000
    },
    {
      "epoch": 1.657724032994314,
      "grad_norm": 8.044781684875488,
      "learning_rate": 2.2371266116761433e-05,
      "loss": 0.5194,
      "step": 103500
    },
    {
      "epoch": 1.6657323616561224,
      "grad_norm": 3.9673469066619873,
      "learning_rate": 2.223779397239796e-05,
      "loss": 0.5217,
      "step": 104000
    },
    {
      "epoch": 1.6737406903179306,
      "grad_norm": 11.519086837768555,
      "learning_rate": 2.210432182803449e-05,
      "loss": 0.5095,
      "step": 104500
    },
    {
      "epoch": 1.681749018979739,
      "grad_norm": 5.464014530181885,
      "learning_rate": 2.197084968367102e-05,
      "loss": 0.5355,
      "step": 105000
    },
    {
      "epoch": 1.6897573476415473,
      "grad_norm": 4.318820476531982,
      "learning_rate": 2.1837377539307547e-05,
      "loss": 0.5205,
      "step": 105500
    },
    {
      "epoch": 1.6977656763033555,
      "grad_norm": 6.407961845397949,
      "learning_rate": 2.1703905394944078e-05,
      "loss": 0.5122,
      "step": 106000
    },
    {
      "epoch": 1.7057740049651637,
      "grad_norm": 8.025530815124512,
      "learning_rate": 2.1570433250580606e-05,
      "loss": 0.5217,
      "step": 106500
    },
    {
      "epoch": 1.713782333626972,
      "grad_norm": 4.854086399078369,
      "learning_rate": 2.1436961106217134e-05,
      "loss": 0.5269,
      "step": 107000
    },
    {
      "epoch": 1.7217906622887802,
      "grad_norm": 4.895215034484863,
      "learning_rate": 2.130348896185366e-05,
      "loss": 0.5468,
      "step": 107500
    },
    {
      "epoch": 1.7297989909505886,
      "grad_norm": 14.803995132446289,
      "learning_rate": 2.117001681749019e-05,
      "loss": 0.5172,
      "step": 108000
    },
    {
      "epoch": 1.7378073196123969,
      "grad_norm": 4.8039021492004395,
      "learning_rate": 2.103654467312672e-05,
      "loss": 0.5071,
      "step": 108500
    },
    {
      "epoch": 1.7458156482742053,
      "grad_norm": 6.83394718170166,
      "learning_rate": 2.0903072528763248e-05,
      "loss": 0.5062,
      "step": 109000
    },
    {
      "epoch": 1.7538239769360136,
      "grad_norm": 3.1579933166503906,
      "learning_rate": 2.0769600384399776e-05,
      "loss": 0.5295,
      "step": 109500
    },
    {
      "epoch": 1.7618323055978218,
      "grad_norm": 5.3173370361328125,
      "learning_rate": 2.0636128240036307e-05,
      "loss": 0.5125,
      "step": 110000
    },
    {
      "epoch": 1.76984063425963,
      "grad_norm": 3.3504600524902344,
      "learning_rate": 2.0502656095672835e-05,
      "loss": 0.5289,
      "step": 110500
    },
    {
      "epoch": 1.7778489629214382,
      "grad_norm": 1.5318541526794434,
      "learning_rate": 2.0369183951309362e-05,
      "loss": 0.519,
      "step": 111000
    },
    {
      "epoch": 1.7858572915832465,
      "grad_norm": 6.516898155212402,
      "learning_rate": 2.0235711806945893e-05,
      "loss": 0.5218,
      "step": 111500
    },
    {
      "epoch": 1.7938656202450547,
      "grad_norm": 5.115590572357178,
      "learning_rate": 2.010223966258242e-05,
      "loss": 0.5187,
      "step": 112000
    },
    {
      "epoch": 1.8018739489068631,
      "grad_norm": 1.8095836639404297,
      "learning_rate": 1.996876751821895e-05,
      "loss": 0.5086,
      "step": 112500
    },
    {
      "epoch": 1.8098822775686714,
      "grad_norm": 4.258097171783447,
      "learning_rate": 1.9835295373855477e-05,
      "loss": 0.5159,
      "step": 113000
    },
    {
      "epoch": 1.8178906062304798,
      "grad_norm": 3.70536732673645,
      "learning_rate": 1.9701823229492004e-05,
      "loss": 0.5177,
      "step": 113500
    },
    {
      "epoch": 1.825898934892288,
      "grad_norm": 4.52922248840332,
      "learning_rate": 1.9568351085128532e-05,
      "loss": 0.5163,
      "step": 114000
    },
    {
      "epoch": 1.8339072635540963,
      "grad_norm": 4.456188678741455,
      "learning_rate": 1.9434878940765063e-05,
      "loss": 0.5166,
      "step": 114500
    },
    {
      "epoch": 1.8419155922159045,
      "grad_norm": 3.5256004333496094,
      "learning_rate": 1.930140679640159e-05,
      "loss": 0.5269,
      "step": 115000
    },
    {
      "epoch": 1.8499239208777127,
      "grad_norm": 3.6694319248199463,
      "learning_rate": 1.916793465203812e-05,
      "loss": 0.5113,
      "step": 115500
    },
    {
      "epoch": 1.857932249539521,
      "grad_norm": 4.273138046264648,
      "learning_rate": 1.903446250767465e-05,
      "loss": 0.5139,
      "step": 116000
    },
    {
      "epoch": 1.8659405782013294,
      "grad_norm": 13.877301216125488,
      "learning_rate": 1.8900990363311178e-05,
      "loss": 0.5241,
      "step": 116500
    },
    {
      "epoch": 1.8739489068631376,
      "grad_norm": 3.783949851989746,
      "learning_rate": 1.876751821894771e-05,
      "loss": 0.5213,
      "step": 117000
    },
    {
      "epoch": 1.881957235524946,
      "grad_norm": 4.728069305419922,
      "learning_rate": 1.8634046074584237e-05,
      "loss": 0.527,
      "step": 117500
    },
    {
      "epoch": 1.8899655641867543,
      "grad_norm": 6.048025131225586,
      "learning_rate": 1.8500573930220764e-05,
      "loss": 0.5311,
      "step": 118000
    },
    {
      "epoch": 1.8979738928485625,
      "grad_norm": 6.48728609085083,
      "learning_rate": 1.8367101785857292e-05,
      "loss": 0.5388,
      "step": 118500
    },
    {
      "epoch": 1.9059822215103708,
      "grad_norm": 4.1666388511657715,
      "learning_rate": 1.823362964149382e-05,
      "loss": 0.5276,
      "step": 119000
    },
    {
      "epoch": 1.913990550172179,
      "grad_norm": 5.920313835144043,
      "learning_rate": 1.8100157497130348e-05,
      "loss": 0.5154,
      "step": 119500
    },
    {
      "epoch": 1.9219988788339872,
      "grad_norm": 5.515158176422119,
      "learning_rate": 1.796668535276688e-05,
      "loss": 0.5377,
      "step": 120000
    },
    {
      "epoch": 1.9300072074957955,
      "grad_norm": 4.867806911468506,
      "learning_rate": 1.7833213208403406e-05,
      "loss": 0.5142,
      "step": 120500
    },
    {
      "epoch": 1.938015536157604,
      "grad_norm": 5.740201473236084,
      "learning_rate": 1.7699741064039934e-05,
      "loss": 0.5121,
      "step": 121000
    },
    {
      "epoch": 1.9460238648194121,
      "grad_norm": 6.0920305252075195,
      "learning_rate": 1.7566268919676465e-05,
      "loss": 0.5073,
      "step": 121500
    },
    {
      "epoch": 1.9540321934812206,
      "grad_norm": 3.8682684898376465,
      "learning_rate": 1.7432796775312993e-05,
      "loss": 0.5235,
      "step": 122000
    },
    {
      "epoch": 1.9620405221430288,
      "grad_norm": 11.944962501525879,
      "learning_rate": 1.729932463094952e-05,
      "loss": 0.5218,
      "step": 122500
    },
    {
      "epoch": 1.970048850804837,
      "grad_norm": 4.42965841293335,
      "learning_rate": 1.7165852486586052e-05,
      "loss": 0.5051,
      "step": 123000
    },
    {
      "epoch": 1.9780571794666453,
      "grad_norm": 2.3707287311553955,
      "learning_rate": 1.703238034222258e-05,
      "loss": 0.51,
      "step": 123500
    },
    {
      "epoch": 1.9860655081284535,
      "grad_norm": 3.7566802501678467,
      "learning_rate": 1.6898908197859107e-05,
      "loss": 0.5182,
      "step": 124000
    },
    {
      "epoch": 1.9940738367902617,
      "grad_norm": 3.688204765319824,
      "learning_rate": 1.6765436053495635e-05,
      "loss": 0.5216,
      "step": 124500
    }
  ],
  "logging_steps": 500,
  "max_steps": 187305,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.3142067108906394e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
